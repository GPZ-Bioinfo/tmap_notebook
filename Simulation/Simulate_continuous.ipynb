{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "import warnings\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.spatial.distance import squareform, pdist\n",
    "from sklearn.cluster import KMeans,DBSCAN\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import *\n",
    "from tmap.netx.SAFE import SAFE_batch, get_SAFE_summary, SAFE_single\n",
    "from tmap.tda import mapper, filter\n",
    "from tmap.tda.metric import Metric\n",
    "from tmap.tda.plot import vis_progressX, Color\n",
    "from tmap.tda.utils import optimize_dbscan_eps, cover_ratio\n",
    "from tmap.tda.cover import Cover\n",
    "from tmap.tda.metric import Metric\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import rpy2.robjects as robjects\n",
    "from rpy2.robjects.packages import importr\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "importr(\"vegan\")\n",
    "\n",
    "def envfit_metadata(genus_path,metadata_path):\n",
    "    rcode = \"\"\"\n",
    "    genus_table <- read.csv('{path_data}',row.names = 1)\n",
    "    metadata <- read.csv('{path_metadata}',row.names = 1)\n",
    "    \n",
    "    bray <- vegdist(genus_table)\n",
    "    ord <- capscale(bray ~ -1)\n",
    "    #plot(ord)\n",
    "    \"\"\".format(path_data=genus_path,path_metadata=metadata_path)\n",
    "    robjects.r(rcode)\n",
    "\n",
    "    envfit_result = robjects.r(\n",
    "    \"\"\"\n",
    "    fit <- envfit(ord,metadata,permutations = 999)\n",
    "    fit$vectors\n",
    "    \"\"\")\n",
    "    fit_result = pd.DataFrame(columns=[\"r\",\"pvals\",\"Source\",\"End\"],index=robjects.r(\"colnames(metadata)\"))\n",
    "    fit_result.loc[:,\"r\"] = envfit_result[envfit_result.names.index(\"r\")]\n",
    "    fit_result.loc[:, \"pvals\"] = envfit_result[envfit_result.names.index(\"pvals\")]\n",
    "    fit_result.loc[:, [\"Source\",\"End\"]] = np.array(envfit_result[envfit_result.names.index(\"arrows\")])\n",
    "    return fit_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "random.seed(100)\n",
    "np.random.seed(100)\n",
    "\n",
    "def get_projected_x(genus_tabs):\n",
    "    tm = mapper.Mapper(verbose=0)\n",
    "    dis = squareform(pdist(genus_tabs, metric=\"braycurtis\"))\n",
    "    metric = Metric(metric=\"precomputed\")\n",
    "    lens = [filter.PCOA(components=[0, 1], metric=metric, random_state=100)]\n",
    "    projected_X = tm.filter(dis, lens=lens)\n",
    "    projected_X = MinMaxScaler().fit_transform(projected_X)\n",
    "    return projected_X\n",
    "\n",
    "def generate_metadata_continuous(projected_X):\n",
    "    p1, p2 = [random.uniform(-1, 1) for i in [1, 2]]\n",
    "    metadata = p1*projected_X[:,0]+p2*projected_X[:,1]\n",
    "\n",
    "    return metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_true_pred(graph,metadata,n_iter,threshold,raw=False):\n",
    "    safe_scores = SAFE_batch(graph, meta_data=metadata, n_iter=n_iter, verbose=0)\n",
    "    safe_summary = get_SAFE_summary(graph,metadata,safe_scores,n_iter,threshold)\n",
    "    y_true = [1 if not _.endswith('fake') else 0 for _ in metadata.columns]\n",
    "    y_pred = [1 if _!=0 else 0 for _ in safe_summary.loc[metadata.columns,'SAFE enriched score']]\n",
    "    if raw:\n",
    "        y_true = [1 if not _.endswith('fake') else 0 for _ in metadata.columns]\n",
    "        y_pred = list(safe_summary.loc[metadata.columns,'SAFE enriched score'])\n",
    "    return y_true,y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "otu_path = 'demo_mat.csv'\n",
    "metadata_path = \"metadata/metadata_linear.csv\"\n",
    "from rpy2.robjects.packages import importr\n",
    "from rpy2.robjects.vectors import FloatVector\n",
    "stats = importr('stats')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering by PCOA.\n",
      "...calculate distance matrix using the precomputed metric.\n",
      "Finish filtering of points cloud data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 458/900 [00:00<00:00, 4577.88it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mapping on data (500, 300) using lens (500, 2)\n",
      "...minimal number of points in hypercube to do clustering: 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 900/900 [00:00<00:00, 4081.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "...create 217 nodes.\n",
      "...calculate projection coordinates of nodes.\n",
      "...construct a TDA graph.\n",
      "...create 1465 edges.\n",
      "Finish TDA mapping\n"
     ]
    }
   ],
   "source": [
    "simulated_otu = pd.read_csv(otu_path, sep=',', index_col=0)\n",
    "simulated_otu = simulated_otu.divide(simulated_otu.sum(1), axis=0)\n",
    "dis = squareform(pdist(simulated_otu, metric=\"braycurtis\"))\n",
    "\n",
    "# generate graph\n",
    "tm = mapper.Mapper(verbose=1)\n",
    "metric = Metric(metric=\"precomputed\")\n",
    "lens = [filter.PCOA(components=[0, 1], metric=metric, random_state=100)]\n",
    "projected_X = tm.filter(dis, lens=lens)\n",
    "eps = optimize_dbscan_eps(simulated_otu, threshold=95)\n",
    "clusterer = DBSCAN(eps=eps, min_samples=3)\n",
    "r = 30\n",
    "cover = Cover(projected_data=MinMaxScaler().fit_transform(projected_X), resolution=r, overlap=0.85)\n",
    "graph = tm.map(data=simulated_otu, cover=cover, clusterer=clusterer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_metadata = 50\n",
    "def continuous(raw=False):\n",
    "    projected_X = get_projected_x(simulated_otu)\n",
    "    metadata = [generate_metadata_continuous(projected_X) for i in range(0, num_metadata)]\n",
    "    metadata = pd.DataFrame(metadata).T\n",
    "    metadata.columns = ['meta' + str(_) for _ in range(1, num_metadata + 1)]\n",
    "\n",
    "    \n",
    "    li_shuffled = metadata.copy().apply(lambda x: np.random.permutation(x),axis=0)\n",
    "    li_shuffled.columns = [_ + '_fake' for _ in li_shuffled.columns]\n",
    "    new_metadata = pd.concat([metadata, li_shuffled], axis=1)\n",
    "\n",
    "    new_metadata.to_csv(metadata_path, index=True)\n",
    "    y_true,y_pred = get_true_pred(graph,new_metadata,n_iter=1000,threshold=0.01,raw=raw)\n",
    "    \n",
    "    fit_result = envfit_metadata(otu_path, metadata_path)\n",
    "    p_adjust = stats.p_adjust(FloatVector(fit_result.pvals.values), method = 'BH')\n",
    "    fit_result[\"BH_corrected\"] = p_adjust\n",
    "    fit_y_true = y_true[::]\n",
    "    if raw:\n",
    "        fit_y_pred = list(fit_result.loc[new_metadata.columns,\"pvals\"])\n",
    "    else:\n",
    "        fit_y_pred = [1 if fit_result.loc[_,'BH_corrected']<=0.05 else 0 for _ in new_metadata.columns]\n",
    "    return y_true,y_pred,fit_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [42:12<00:00, 25.33s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import trange\n",
    "\n",
    "res = []\n",
    "for i in trange(0,100):\n",
    "    y_true,y_pred,fit_y_pred = continuous(raw=True)\n",
    "    res.append((y_true,y_pred,fit_y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# basic rule\n",
    "fsafe_recall = lambda x: recall_score(x[0],[1 if _ !=0 else 0 for _ in x[1]])\n",
    "fsafe_precision = lambda x: precision_score(x[0],[1 if _!=0 else 0 for _ in x[1]])\n",
    "fenvfit_recall = lambda x: recall_score(x[0],[1 if _<=0.05 else 0 for _ in x[2]])\n",
    "fenvfit_precision = lambda x: precision_score(x[0],[1 if _<=0.05 else 0 for _ in x[2]])\n",
    "fsafe_f1 = lambda x: f1_score(x[0],[1 if _ !=0 else 0 for _ in x[1]])\n",
    "fenvfit_f1 = lambda x: f1_score(x[0],[1 if _<=0.05 else 0 for _ in x[2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output raw y_true and y_pred\n",
    "tmp = []\n",
    "for idx,_ in enumerate(res):\n",
    "    cache = pd.DataFrame(np.array(_).T,columns=['y_true_%s' % idx,\n",
    "                                                'y_pred_%s' % idx,\n",
    "                                                'y_envfit_%s' % idx])\n",
    "    tmp.append(cache)\n",
    "raw_result = pd.concat(tmp,axis=1)\n",
    "raw_result.to_csv('plot_data/linear_100_raw.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
